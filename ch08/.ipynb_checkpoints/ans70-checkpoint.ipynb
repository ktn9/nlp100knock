{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer as PS\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../ch07/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "ps = PS() #steming用\n",
    "\n",
    "train = pd.read_table('train.txt', header=None)\n",
    "valid = pd.read_table('valid.txt', header=None)\n",
    "test = pd.read_table('test.txt', header=None)\n",
    "\n",
    "cols = ['CATEGORY', 'TITLE']\n",
    "train.columns = cols\n",
    "valid.columns = cols\n",
    "test.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#出現頻度の高い単語の除去\n",
    "def remove_stopwords(text):\n",
    "    #入力と出力は同じstring形式\n",
    "    stop_words = set(stopwords.words(\"english\")) #stopwords\n",
    "    \n",
    "    #文区切りと単語区切りを順に行い　単語をストップワードと照らし合わせる\n",
    "    period=[]\n",
    "    for i in re.split(\"[.]\",text):\n",
    "        word=[j for j in i.split(\" \") if j != \"\" and j not in stop_words]\n",
    "        period.append(word)\n",
    "        word=[]\n",
    "    \n",
    "    #元の形に復元\n",
    "    tmp=[]\n",
    "    for k in period:\n",
    "        if k != []:\n",
    "            tmp.append(' '.join(k))\n",
    "\n",
    "    result='.'.join(tmp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    replaced_text = text.lower()\n",
    "    replaced_text = re.sub(r'[【】]', '', replaced_text)       # 【】の除去\n",
    "    replaced_text = re.sub(r'[（）()]', '', replaced_text)     # （）の除去\n",
    "    replaced_text = re.sub(r'[［］\\[\\]]', '', replaced_text)   # ［］の除去\n",
    "    replaced_text = re.sub(r'[{}\\{\\}]', '', replaced_text)   #  {}\n",
    "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "    replaced_text = re.sub(r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
    "    replaced_text = re.sub(r'\\-',' ', replaced_text) #ハイフンは空白へ\n",
    "    replaced_text = re.sub(r'　', ' ', replaced_text) # 全角空白の除去\n",
    "    replaced_text = re.sub(r'  ', '', replaced_text) #２連続の半角空白を1つに\n",
    "    replaced_text = re.sub(r'\\d+\\.\\d+','', replaced_text) #小数点を含む数列の除去\n",
    "    replaced_text = re.sub(r'\\;','', replaced_text) #セミコロン\n",
    "    replaced_text = re.sub(r'\\:','', replaced_text) #コロン\n",
    "    replaced_text = re.sub(r'\\'','', replaced_text) #クオーテーション\n",
    "    replaced_text = re.sub(r'\\`','', replaced_text) #クオーテーション\n",
    "    replaced_text = re.sub(r'\\,','', replaced_text) #カンマ\n",
    "    replaced_text = re.sub(r'\\_','', replaced_text) #アンダーバー\n",
    "    replaced_text = re.sub(r'\\\\','', replaced_text) #バックスラッシュ\n",
    "    replaced_text = re.sub(r'\\?','', replaced_text) #クエスチョン\n",
    "    replaced_text = re.sub(r'\\!','', replaced_text) #感嘆符　（ピリオドど同様に文末に使われる）\n",
    "    replaced_text = re.sub(r'\\+','', replaced_text) #プラス\n",
    "    replaced_text = re.sub(r'\\*','', replaced_text) #アスタリスク\n",
    "    replaced_text = re.sub(r'\\/','', replaced_text) #スラッシュ\n",
    "    replaced_text = re.sub(r'\\<','', replaced_text) #小なり\n",
    "    replaced_text = re.sub(r'\\>','', replaced_text) #大なり\n",
    "    replaced_text = re.sub(r'\\=','', replaced_text) #イコール\n",
    "    replaced_text = re.sub(r'\\%','', replaced_text) #パーセント\n",
    "    replaced_text = re.sub(r'\\&','', replaced_text) #アンパサント\n",
    "    replaced_text = re.sub(r'\\$','', replaced_text) #ドル\n",
    "    replaced_text = re.sub(r'\\#','', replaced_text) #シャープ\n",
    "    replaced_text = re.sub(r'.\\..\\.','', replaced_text) #U.S. or U.N.の除去\n",
    "    #replaced_text = re.sub(r'\\d+','', replaced_text) #数列の除去\n",
    "    replaced_text = re.sub(r'\\d{1,3}','', replaced_text) #1から3桁の数列の除去\n",
    "    replaced_text = re.sub(r'\\d{5,}','', replaced_text) #5桁以上の数列の除去\n",
    "    replaced_text = ps.stem(\"%s\" % replaced_text) #語幹抽出\n",
    "    return remove_stopwords(replaced_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"shaped_txt\"] = list(map(clean_text,train[\"TITLE\"]))\n",
    "valid[\"shaped_txt\"] = list(map(clean_text,valid[\"TITLE\"]))\n",
    "test[\"shaped_txt\"] = list(map(clean_text,test[\"TITLE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"type\"] = \"train\"\n",
    "valid[\"type\"] = \"valid\"\n",
    "test[\"type\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, valid, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(data['CATEGORY'])\n",
    "data['label'] = le.transform(data['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>shaped_txt</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m</td>\n",
       "      <td>The Flu Tricked Google. Can Wikipedia Do Better?</td>\n",
       "      <td>flu tricked google.wikipedia bett</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>UPDATE 2-ECB's Constancio watching more than j...</td>\n",
       "      <td>update ecbs constancio watching april inflatio...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>Amazon to unveil smartphone in time for holida...</td>\n",
       "      <td>amazon unveil smartphone time holidayswsj</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>Mighty Morphin Power Rangers - Power Rangers F...</td>\n",
       "      <td>mighty morphin power rangers power rangers fea...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m</td>\n",
       "      <td>Biogen Idec wins Canadian approval for hemophi...</td>\n",
       "      <td>biogen idec wins canadian approval hemophilia ...</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10880</th>\n",
       "      <td>m</td>\n",
       "      <td>STOCKS NEWS EUROPE-Novartis jumps on positive ...</td>\n",
       "      <td>stocks news europe novartis jumps positive hea...</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10881</th>\n",
       "      <td>e</td>\n",
       "      <td>Bachelor Juan Pablo Galavis chooses Nikki Ferr...</td>\n",
       "      <td>bachelor juan pablo galavis chooses nikki ferr...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10882</th>\n",
       "      <td>b</td>\n",
       "      <td>Kingfisher Starts Returning Cash as Confidence...</td>\n",
       "      <td>kingfisher starts returning cash confidence ou...</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>t</td>\n",
       "      <td>EPA says Ford to correct fuel economy standard...</td>\n",
       "      <td>epa says ford correct fuel economy standard si...</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10884</th>\n",
       "      <td>b</td>\n",
       "      <td>China's factories spring to life as global tra...</td>\n",
       "      <td>chinas factories spring life global trade reaw...</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10885 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CATEGORY                                              TITLE  \\\n",
       "0            m   The Flu Tricked Google. Can Wikipedia Do Better?   \n",
       "1            b  UPDATE 2-ECB's Constancio watching more than j...   \n",
       "2            t  Amazon to unveil smartphone in time for holida...   \n",
       "3            e  Mighty Morphin Power Rangers - Power Rangers F...   \n",
       "4            m  Biogen Idec wins Canadian approval for hemophi...   \n",
       "...        ...                                                ...   \n",
       "10880        m  STOCKS NEWS EUROPE-Novartis jumps on positive ...   \n",
       "10881        e  Bachelor Juan Pablo Galavis chooses Nikki Ferr...   \n",
       "10882        b  Kingfisher Starts Returning Cash as Confidence...   \n",
       "10883        t  EPA says Ford to correct fuel economy standard...   \n",
       "10884        b  China's factories spring to life as global tra...   \n",
       "\n",
       "                                              shaped_txt   type  label  \n",
       "0                      flu tricked google.wikipedia bett  train      2  \n",
       "1      update ecbs constancio watching april inflatio...  train      0  \n",
       "2              amazon unveil smartphone time holidayswsj  train      3  \n",
       "3      mighty morphin power rangers power rangers fea...  train      1  \n",
       "4      biogen idec wins canadian approval hemophilia ...  train      2  \n",
       "...                                                  ...    ...    ...  \n",
       "10880  stocks news europe novartis jumps positive hea...   test      2  \n",
       "10881  bachelor juan pablo galavis chooses nikki ferr...   test      1  \n",
       "10882  kingfisher starts returning cash confidence ou...   test      0  \n",
       "10883  epa says ford correct fuel economy standard si...   test      3  \n",
       "10884  chinas factories spring life global trade reaw...   test      0  \n",
       "\n",
       "[10885 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {}\n",
    "for name, group in data.groupby('type'):\n",
    "    df_dict[name] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>shaped_txt</th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m</td>\n",
       "      <td>The Flu Tricked Google. Can Wikipedia Do Better?</td>\n",
       "      <td>flu tricked google.wikipedia bett</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>UPDATE 2-ECB's Constancio watching more than j...</td>\n",
       "      <td>update ecbs constancio watching april inflatio...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>Amazon to unveil smartphone in time for holida...</td>\n",
       "      <td>amazon unveil smartphone time holidayswsj</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>Mighty Morphin Power Rangers - Power Rangers F...</td>\n",
       "      <td>mighty morphin power rangers power rangers fea...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m</td>\n",
       "      <td>Biogen Idec wins Canadian approval for hemophi...</td>\n",
       "      <td>biogen idec wins canadian approval hemophilia ...</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8703</th>\n",
       "      <td>b</td>\n",
       "      <td>Delaware Probing Tilting Bridge Clogging Inter...</td>\n",
       "      <td>delaware probing tilting bridge clogging inter...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>m</td>\n",
       "      <td>African Camels Show MERS Virus Is More Widespr...</td>\n",
       "      <td>african camels show mers virus widespread believ</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8705</th>\n",
       "      <td>t</td>\n",
       "      <td>UPDATE 3-GM recalls half million Camaros, safe...</td>\n",
       "      <td>update gm recalls half million camaros safety ...</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8706</th>\n",
       "      <td>b</td>\n",
       "      <td>REFILE-Euro zone manufacturing growth eases in...</td>\n",
       "      <td>refile euro zone manufacturing growth eases ju...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>e</td>\n",
       "      <td>Tech guru who said virgin killer's sister was ...</td>\n",
       "      <td>tech guru said virgin killers sister probably ...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8708 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CATEGORY                                              TITLE  \\\n",
       "0           m   The Flu Tricked Google. Can Wikipedia Do Better?   \n",
       "1           b  UPDATE 2-ECB's Constancio watching more than j...   \n",
       "2           t  Amazon to unveil smartphone in time for holida...   \n",
       "3           e  Mighty Morphin Power Rangers - Power Rangers F...   \n",
       "4           m  Biogen Idec wins Canadian approval for hemophi...   \n",
       "...       ...                                                ...   \n",
       "8703        b  Delaware Probing Tilting Bridge Clogging Inter...   \n",
       "8704        m  African Camels Show MERS Virus Is More Widespr...   \n",
       "8705        t  UPDATE 3-GM recalls half million Camaros, safe...   \n",
       "8706        b  REFILE-Euro zone manufacturing growth eases in...   \n",
       "8707        e  Tech guru who said virgin killer's sister was ...   \n",
       "\n",
       "                                             shaped_txt   type  label  \n",
       "0                     flu tricked google.wikipedia bett  train      2  \n",
       "1     update ecbs constancio watching april inflatio...  train      0  \n",
       "2             amazon unveil smartphone time holidayswsj  train      3  \n",
       "3     mighty morphin power rangers power rangers fea...  train      1  \n",
       "4     biogen idec wins canadian approval hemophilia ...  train      2  \n",
       "...                                                 ...    ...    ...  \n",
       "8703  delaware probing tilting bridge clogging inter...  train      0  \n",
       "8704   african camels show mers virus widespread believ  train      2  \n",
       "8705  update gm recalls half million camaros safety ...  train      3  \n",
       "8706  refile euro zone manufacturing growth eases ju...  train      0  \n",
       "8707  tech guru said virgin killers sister probably ...  train      1  \n",
       "\n",
       "[8708 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_train.joblib']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "for i in df_dict['train']['shaped_txt']:\n",
    "    X_train.append(np.mean([model[i] for i in i.split() if i in model.vocab],axis=0))\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "y_train = np.array(df_dict['train']['label'])\n",
    "\n",
    "joblib.dump(X_train,'X_train.joblib')\n",
    "joblib.dump(y_train,'y_train.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_valid.joblib']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = []\n",
    "for i in df_dict['valid']['shaped_txt']:\n",
    "    X_valid.append(np.mean([model[i] for i in i.split() if i in model.vocab],axis=0))\n",
    "X_valid = np.array(X_valid)\n",
    "\n",
    "y_valid = np.array(df_dict['valid']['label'])\n",
    "\n",
    "joblib.dump(X_valid,'X_valid.joblib')\n",
    "joblib.dump(y_valid,'y_valid.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test.joblib']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = []\n",
    "for i in df_dict['test']['shaped_txt']:\n",
    "    X_test.append(np.mean([model[i] for i in i.split() if i in model.vocab],axis=0))\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = np.array(df_dict['test']['label'])\n",
    "\n",
    "joblib.dump(X_test,'X_test.joblib')\n",
    "joblib.dump(y_test,'y_test.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
